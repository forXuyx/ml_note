{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  I  made some modifications for this sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Operations\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Reading/Writing Data\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# For Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        '''***********- model params -*************'''\n",
    "        self.model_name = \"hw1\"\n",
    "\n",
    "        '''***********- data path -*************'''\n",
    "        self.data_path = '../../../data/hw1/'\n",
    "        self.train_file='covid.train.csv'\n",
    "        self.val_file = ''\n",
    "        self.test_file = 'covid.test.csv'\n",
    "        self.submit_file = '../../../submit/{}.csv'.format(self.model_name)\n",
    "\n",
    "        '''***********- model path -*************'''\n",
    "        self.MODEL_PATH = '../../../ckpts/{}'.format(self.model_name)\n",
    "        if not os.path.exists(self.MODEL_PATH):\n",
    "            os.makedirs(self.MODEL_PATH)\n",
    "\n",
    "        '''***********- cpu or gpu and dara parallel -*************'''\n",
    "        # self.gpus = [] # cpu\n",
    "        # self.gpus = [0] # single gpu\n",
    "        self.gpus = [0] # multi gpu\n",
    "        self.WORKERS = 5 # num of workers for data loader\n",
    "\n",
    "        '''***********- Hyper Arguments -*************'''\n",
    "        self.rand_seed=40\n",
    "        self.batch_size = 256\n",
    "        self.lr = 1e-5\n",
    "        self.epochs = 200\n",
    "        self.split_ratio = 0.2\n",
    "        self.momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(data_set, valid_ratio, seed):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set)) \n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set), np.array(valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        self.x = torch.FloatTensor(x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        # TODO: modify model's structure, be aware of dimensions. \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1) # (B, 1) -> (B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feat(train_data, valid_data, test_data, select_all=True):\n",
    "    '''Selects useful features to perform regression'''\n",
    "    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
    "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n",
    "\n",
    "    if select_all:\n",
    "        feat_idx = list(range(raw_x_train.shape[1]))\n",
    "    else:\n",
    "        # 计算每个特征与y_train的相关系数\n",
    "        correlations = np.array([np.corrcoef(raw_x_train[:, i], y_train)[0, 1] for i in range(raw_x_train.shape[1])])\n",
    "        # 选择相关系数绝对值大于0.1的特征\n",
    "        feat_idx = np.where(np.abs(correlations) > 0.1)[0]\n",
    "        \n",
    "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer():\n",
    "    print(\"***********- ***********- Init -*************\")\n",
    "    args = Args()\n",
    "\n",
    "    print(\"***********- ***********- Read data and processing -*************\")\n",
    "    print(\"Loading data...\")\n",
    "    train_data = pd.read_csv(args.data_path+args.train_file).values\n",
    "    test_data = pd.read_csv(args.data_path+args.test_file).values\n",
    "    train_data, valid_data = train_valid_split(train_data, args.split_ratio, args.rand_seed)\n",
    "    # Print out the data size.\n",
    "    print(f\"\"\"train_data size: {train_data.shape} \n",
    "          valid_data size: {valid_data.shape} \n",
    "          test_data size: {test_data.shape}\"\"\")\n",
    "\n",
    "    print(\"Selecting features...\")\n",
    "    x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, select_all=False)\n",
    "    # Print out the number of features.\n",
    "    print(f'number of features: {x_train.shape[1]}')\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n",
    "                                                COVID19Dataset(x_valid, y_valid), \\\n",
    "                                                COVID19Dataset(x_test)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=args.WORKERS)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=args.WORKERS)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=args.WORKERS)\n",
    "\n",
    "    print(\"***********- ***********- Loading model -*************\")\n",
    "    if(len(args.gpus) == 0):\n",
    "        model = My_Model(input_dim=x_train.shape[1])\n",
    "        print(\"***********- ***********- Using CPU -*************\")\n",
    "    elif(len(args.gpus) == 1):\n",
    "        model = My_Model(input_dim=x_train.shape[1]).cuda()\n",
    "        print(\"***********- ***********- Using Single GPU -*************\")\n",
    "    else:\n",
    "        gpus = ','.join(str(i) for i in args.gpus)\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus\n",
    "        model = My_Model(input_dim=x_train.shape[1]).cuda()\n",
    "        gpus = [i for i in range(len(args.gpus))]\n",
    "        model = torch.nn.DataParallel(model, device_ids=gpus)\n",
    "        print(\"***********- ***********- Using Multi GPU -*************\")\n",
    "    \n",
    "    model_best_path=args.MODEL_PATH+'/{}_best_params.pth'.format(args.model_name)\n",
    "    model_final_path=args.MODEL_PATH+'/{}_final_params.pth'.format(args.model_name)\n",
    "    \n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    print(\"***********- ***********- Training begin -*************\")\n",
    "    train_epochs_loss = []\n",
    "    # train_epochs_mse = []\n",
    "    valid_epochs_loss = []\n",
    "    # valid_epochs_mse = []\n",
    "    val_inf = 1e9\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        train_epoch_loss = []\n",
    "        # train_epoch_mse = []\n",
    "        # =========================train=======================\n",
    "        for idx, (X, y) in enumerate(tqdm(train_dataloader)):\n",
    "            if (len(args.gpus) > 0):\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "            outputs = model(X)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, y)\n",
    "            # mse = torch.nn.functional.mse_loss(outputs, y)\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0) #用来梯度裁剪\n",
    "            optimizer.step()\n",
    "            train_epoch_loss.append(loss.item())\n",
    "            # train_epoch_mse.append(mse.item())\n",
    "        train_epochs_loss.append(np.average(train_epoch_loss))\n",
    "        # train_epochs_mse.append(np.average(train_epoch_mse))\n",
    "        # print(\"Train epoch = {}, loss = {:.4f}, mse = {:.4f}\".format(epoch + 1, np.average(train_epoch_loss), np.average(train_epoch_mse)))\n",
    "        print(\"Train epoch = {}, loss = {:.4f}\".format(epoch + 1, np.average(train_epoch_loss)))\n",
    "        # =========================val=========================\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_epoch_loss = []\n",
    "            # val_epoch_mse = []\n",
    "            for idx, (X, y) in enumerate(tqdm(val_dataloader)):\n",
    "                if (len(args.gpus) > 0):\n",
    "                    X, y = X.cuda(), y.cuda()\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                # mse = torch.nn.functional.mse_loss(outputs, y)\n",
    "                val_epoch_loss.append(loss.item())\n",
    "                # val_epoch_mse.append(mse.item())\n",
    "            if np.average(val_epoch_loss) < val_inf:\n",
    "                val_inf = np.average(val_epoch_loss)\n",
    "                torch.save(model.state_dict(), model_best_path)\n",
    "            valid_epochs_loss.append(np.average(val_epoch_loss))\n",
    "            # valid_epochs_mse.append(np.average(val_epoch_mse))\n",
    "            # print(\"Valid epoch = {}, loss = {:.4f}, mse = {:.4f}\".format(epoch + 1, np.average(val_epoch_loss), np.average(val_epoch_mse)))\n",
    "            print(\"Valid epoch = {}, loss = {:.4f}\".format(epoch + 1, np.average(val_epoch_loss)))\n",
    "            \n",
    "    torch.save(model.state_dict(), model_final_path)\n",
    "    print(\"***********- ***********- Training finished -*************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tester(final=True):\n",
    "    print(\"***********- ***********- Init -*************\")\n",
    "    args = Args()\n",
    "\n",
    "    print(\"***********- ***********- Read data and processing -*************\")\n",
    "    print(\"Loading data...\")\n",
    "    train_data = pd.read_csv(args.data_path+args.train_file).values\n",
    "    test_data = pd.read_csv(args.data_path+args.test_file).values\n",
    "    train_data, valid_data = train_valid_split(train_data, args.split_ratio, args.rand_seed)\n",
    "\n",
    "    print(\"Selecting features...\")\n",
    "    x_train, _, x_test, _, _ = select_feat(train_data, valid_data, test_data, select_all=False)\n",
    "\n",
    "    test_dataset = COVID19Dataset(x_test)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=args.WORKERS)\n",
    "\n",
    "    print(\"***********- ***********- Loading model -*************\")\n",
    "    if(len(args.gpus) == 0):\n",
    "        model = My_Model(input_dim=x_train.shape[1])\n",
    "        print(\"***********- ***********- Using CPU -*************\")\n",
    "    elif(len(args.gpus) == 1):\n",
    "        model = My_Model(input_dim=x_train.shape[1]).cuda()\n",
    "        print(\"***********- ***********- Using Single GPU -*************\")\n",
    "    else:\n",
    "        gpus = ','.join(str(i) for i in args.gpus)\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus\n",
    "        model = My_Model(input_dim=x_train.shape[1]).cuda()\n",
    "        gpus = [i for i in range(len(args.gpus))]\n",
    "        model = torch.nn.DataParallel(model, device_ids=gpus)\n",
    "        print(\"***********- ***********- Using Multi GPU -*************\")\n",
    "    \n",
    "    model_best_path=args.MODEL_PATH+'/{}_best_params.pth'.format(args.model_name)\n",
    "    model_final_path=args.MODEL_PATH+'/{}_final_params.pth'.format(args.model_name)\n",
    "    \n",
    "    if final:\n",
    "        model.load_state_dict(torch.load(model_final_path))\n",
    "        print(\"***********- ***********- Using Final Model -*************\")\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_best_path))\n",
    "        print(\"***********- ***********- Using Best Model -*************\")\n",
    "\n",
    "    print(\"***********- ***********- Test begin -*************\")\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    # =========================test=======================\n",
    "    for idx, (X) in enumerate(tqdm(test_dataloader)):\n",
    "        if (len(args.gpus) > 0):\n",
    "            X = X.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X)\n",
    "            preds.append(outputs.detach().cpu())\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "\n",
    "    print(\"***********- ***********- Save predictions -*************\")\n",
    "    save_file = args.submit_file\n",
    "    with open(save_file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "    print(\"***********- ***********- Test finished -*************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester(final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
